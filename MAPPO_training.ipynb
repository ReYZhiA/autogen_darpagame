{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "\n",
    "# Tensordict modules\n",
    "from tensordict import TensorDict\n",
    "from tensordict.nn import TensorDictModule\n",
    "from tensordict.nn.distributions import NormalParamExtractor\n",
    "from torch import multiprocessing\n",
    "\n",
    "# Data collection\n",
    "from torchrl.collectors import SyncDataCollector\n",
    "from torchrl.data.replay_buffers import ReplayBuffer\n",
    "from torchrl.data.replay_buffers.samplers import SamplerWithoutReplacement\n",
    "from torchrl.data.replay_buffers.storages import LazyTensorStorage\n",
    "\n",
    "# Env\n",
    "from torchrl.envs import RewardSum, TransformedEnv\n",
    "from torchrl.envs.libs.vmas import VmasEnv\n",
    "from torchrl.envs.utils import check_env_specs\n",
    "\n",
    "# Multi-agent network\n",
    "from torchrl.modules import MultiAgentMLP, ProbabilisticActor, TanhNormal\n",
    "\n",
    "# Loss\n",
    "from torchrl.objectives import ClipPPOLoss, ValueEstimators\n",
    "\n",
    "# Utils\n",
    "torch.manual_seed(0)\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Dragon Env\n",
    "from gym_dragon.dragon import MiniDragonBaseEnv\n",
    "from gym_dragon.core import Region, Agent, Tool, Bomb\n",
    "from gym_dragon.wrappers import MiniObs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Devices\n",
    "is_fork = multiprocessing.get_start_method() == \"fork\"\n",
    "device = (\n",
    "    torch.device(0)\n",
    "    if torch.cuda.is_available() and not is_fork\n",
    "    else torch.device(\"cpu\")\n",
    ")\n",
    "vmas_device = device  # The device where the simulator is run (VMAS can run on GPU)\n",
    "\n",
    "# Sampling\n",
    "frames_per_batch = 6_000  # Number of team frames collected per training iteration\n",
    "n_iters = 15  # Number of sampling and training iterations\n",
    "total_frames = frames_per_batch * n_iters\n",
    "\n",
    "# Training\n",
    "num_epochs = 30  # Number of optimization steps per training iteration\n",
    "minibatch_size = 400  # Size of the mini-batches in each optimization step\n",
    "lr = 3e-4  # Learning rate\n",
    "max_grad_norm = 1.0  # Maximum norm for the gradients\n",
    "\n",
    "# PPO\n",
    "clip_epsilon = 0.2  # clip value for PPO loss\n",
    "gamma = 0.99  # discount factor\n",
    "lmbda = 0.9  # lambda for generalised advantage estimation\n",
    "entropy_eps = 1e-4  # coefficient of the entropy term in the PPO loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_steps = 100  # Episode steps before done\n",
    "num_vmas_envs = (\n",
    "    frames_per_batch // max_steps\n",
    ")  # Number of vectorized envs. frames_per_batch should be divisible by this number\n",
    "scenario_name = \"navigation\"\n",
    "n_agents = 5\n",
    "\n",
    "env = VmasEnv(\n",
    "    scenario=scenario_name,\n",
    "    num_envs=num_vmas_envs,\n",
    "    continuous_actions=True,  # VMAS supports both continuous and discrete actions\n",
    "    max_steps=max_steps,\n",
    "    device=vmas_device,\n",
    "    # Scenario kwargs\n",
    "    n_agents=n_agents,  # These are custom kwargs that change for each VMAS scenario, see the VMAS repo to know more.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self, **kwargs):\n",
    "        for k, v in kwargs.items():\n",
    "            setattr(self, k, v)\n",
    "        self.round_id = 0\n",
    "\n",
    "\n",
    "default_actions = np.zeros((n_agents, 9))\n",
    "default_values = {\n",
    "    \"save_path\": \"RL/data\",\n",
    "    \"seed\": 0,\n",
    "    \"tool_per_agent\": 2,\n",
    "    \"max_steps\": 30,\n",
    "    \"actions\": default_actions,\n",
    "}\n",
    "\n",
    "args = Args(**default_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(args.save_path):\n",
    "    os.makedirs(args.save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    **Action Space**\n",
    "\n",
    "    The environment uses a discrete action space, with actions consisting of the following:\n",
    "\n",
    "    * Action.unfreeze_agents\n",
    "        Unfreeze agents at the current node\n",
    "    * Action.inspect_bomb\n",
    "        Inspect a bomb at the current node\n",
    "    * Action.find_next_bomb\n",
    "        Update the agent's observation with the next bomb in the current node\n",
    "    * Action.place_bomb_beacon\n",
    "        Place a bomb beacon at the current node\n",
    "    * Action.place_help_beacon\n",
    "        Place a help beacon at the current node\n",
    "    * Action.remove_bomb_beacon\n",
    "        Remove a bomb beacon from the current node\n",
    "    * Action.remove_help_beacon\n",
    "        Remove a help beacon from the current node\n",
    "    * Action.go_to(node_id)\n",
    "        Move the agent to the specified node\n",
    "    * Action.use_tool(tool)\n",
    "        Apply the specified tool to the current node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    **Observation Space**\n",
    "\n",
    "    A standard observation for each agent contains the following items:\n",
    "\n",
    "    * 'agents'\n",
    "        An array of shape (num_agents, num_agent_features)\n",
    "    * 'graph'\n",
    "        An array of shape (num_nodes, num_node_features)\n",
    "    * 'action_mask'\n",
    "        An array of shape (num_actions,)\n",
    "\n",
    "    See **gym_dragon.core.observation** module for more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDragonEnv(MiniDragonBaseEnv):\n",
    "    def __init__(self, agents, **kwargs):\n",
    "        self._agents = agents  # Set the agents attribute before calling super\n",
    "        super().__init__(**kwargs)  # Ensure all kwargs are passed to the base class\n",
    "\n",
    "    @property\n",
    "    def agents(self):\n",
    "        return self._agents\n",
    "\n",
    "    @agents.setter\n",
    "    def agents(self, value):\n",
    "        self._agents = value\n",
    "\n",
    "    @property\n",
    "    def observation_spec(self):\n",
    "        # Define observation_spec\n",
    "        return {\"agents\": {\"observation\": torch.zeros((len(self.agents), 36))}}\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        # Call the parent class's reset method\n",
    "        raw_obs = super().reset(**kwargs)\n",
    "        # Convert raw_obs to TensorDict\n",
    "        obs = TensorDict(\n",
    "            {\n",
    "                \"agents\": {\n",
    "                    \"observation\": torch.stack(\n",
    "                        [torch.tensor(raw_obs[agent]) for agent in self._agents]\n",
    "                    )\n",
    "                }\n",
    "            },\n",
    "            batch_size=[len(self._agents)],\n",
    "            device=torch.device(\"cpu\"),\n",
    "        )\n",
    "        return obs\n",
    "\n",
    "    def step(self, actions):\n",
    "        obs, reward, done, info = super().step(actions)\n",
    "        return obs, reward, done, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dragon Env actions are Discrete(9)\n",
    "agents = [\"alpha\", \"bravo\", \"charlie\"]\n",
    "env = CustomDragonEnv(\n",
    "    agents=agents,\n",
    "    mission_length=999,\n",
    "    recon_phase_length=0,\n",
    "    include_chained_bombs=False,\n",
    "    include_fire_bombs=False,\n",
    "    include_fuse_bombs=False,\n",
    "    color_tools_only=True,\n",
    "    obs_wrapper=MiniObs,\n",
    ")\n",
    "env.seed(args.seed)\n",
    "if args.tool_per_agent == 2:\n",
    "    env.reset(\n",
    "        csv_path=None,\n",
    "        num_bombs_per_region=5,\n",
    "        start_location=None,\n",
    "        start_regions=set(Region.village),\n",
    "        tool_allocation={\n",
    "            \"alpha\": {Tool.red: 99, Tool.green: 99},\n",
    "            \"bravo\": {Tool.blue: 99, Tool.green: 99},\n",
    "            \"charlie\": {Tool.red: 99, Tool.blue: 99},\n",
    "        },\n",
    "    )\n",
    "else:\n",
    "    env.reset(\n",
    "        csv_path=None,\n",
    "        num_bombs_per_region=5,\n",
    "        start_location=None,\n",
    "        start_regions=set(Region.village),\n",
    "        tool_allocation={\n",
    "            \"alpha\": {Tool.red: 99},\n",
    "            \"bravo\": {Tool.green: 99},\n",
    "            \"charlie\": {Tool.blue: 99},\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.get_agent_ids()\n",
    "# env.render()\n",
    "Action = env.action_enum\n",
    "obs = env._get_obs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs[\"alpha\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obs, rewards, done, info = env.step(actions=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = TransformedEnv(\n",
    "#     env,\n",
    "#     RewardSum(in_keys=[env.reward_key], out_keys=[(\"agents\", \"episode_reward\")]),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_rollout_steps = 3\n",
    "# rollout = env.rollout(n_rollout_steps)\n",
    "# print(\"rollout of three steps:\", rollout)\n",
    "# print(\"Shape of the rollout TensorDict:\", rollout.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "share_parameters_policy = True\n",
    "\n",
    "policy_net = torch.nn.Sequential(\n",
    "    MultiAgentMLP(\n",
    "        n_agent_inputs=36,\n",
    "        n_agent_outputs=9,\n",
    "        n_agents=len(env.agents),\n",
    "        centralised=False,  # the policies are decentralised (ie each agent will act from its observation)\n",
    "        share_params=share_parameters_policy,\n",
    "        device=device,\n",
    "        depth=2,\n",
    "        num_cells=256,\n",
    "        activation_class=torch.nn.Tanh,\n",
    "    ),\n",
    "    NormalParamExtractor(),  # Rm for discrete actions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_module = TensorDictModule(\n",
    "    policy_net,\n",
    "    in_keys=[(\"agents\", \"observation\")],\n",
    "    out_keys=[(\"agents\", \"loc\"), (\"agents\", \"scale\")],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = ProbabilisticActor(\n",
    "    module=policy_module,\n",
    "    # spec=env.unbatched_action_spec,\n",
    "    in_keys=[(\"agents\", \"loc\"), (\"agents\", \"scale\")],\n",
    "    out_keys=[(\"agents\", \"actions\")],\n",
    "    distribution_class=TanhNormal,\n",
    "    # distribution_kwargs={\n",
    "    #     \"min\": env.unbatched_action_spec[env.action_key].space.low,\n",
    "    #     \"max\": env.unbatched_action_spec[env.action_key].space.high,\n",
    "    # },\n",
    "    return_log_prob=True,\n",
    "    log_prob_key=(\"agents\", \"sample_log_prob\"),\n",
    ")  # we'll need the log-prob for the PPO loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial state: TensorDict(\n",
      "    fields={\n",
      "        agents: TensorDict(\n",
      "            fields={\n",
      "                observation: Tensor(shape=torch.Size([3, 36]), device=cpu, dtype=torch.float64, is_shared=False)},\n",
      "            batch_size=torch.Size([3]),\n",
      "            device=cpu,\n",
      "            is_shared=False)},\n",
      "    batch_size=torch.Size([3]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n",
      "State TensorDict: TensorDict(\n",
      "    fields={\n",
      "        agents: TensorDict(\n",
      "            fields={\n",
      "                observation: Tensor(shape=torch.Size([3, 36]), device=cuda:0, dtype=torch.float64, is_shared=True)},\n",
      "            batch_size=torch.Size([3]),\n",
      "            device=cuda:0,\n",
      "            is_shared=True)},\n",
      "    batch_size=torch.Size([3]),\n",
      "    device=cuda:0,\n",
      "    is_shared=True)\n",
      "Error during policy forward pass: mat1 and mat2 must have the same dtype, but got Double and Float\n"
     ]
    }
   ],
   "source": [
    "# Reset environment and print initial state\n",
    "state = env.reset()\n",
    "print(\"Initial state:\", state)\n",
    "\n",
    "# Convert state to the required format\n",
    "state_tensor = state[\"agents\"][\"observation\"].to(device)\n",
    "\n",
    "# Prepare state dictionary\n",
    "state_dict = TensorDict(\n",
    "    {\"agents\": {\"observation\": state_tensor}}, batch_size=[len(agents)], device=device\n",
    ")\n",
    "print(\"State TensorDict:\", state_dict)\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# Define a dummy policy for testing\n",
    "class DummyPolicy(nn.Module):\n",
    "    def forward(self, x):\n",
    "        logits = torch.randn(x[\"agents\"][\"observation\"].shape[0], 9, device=device)\n",
    "        return {\"action\": logits}\n",
    "\n",
    "\n",
    "# policy = DummyPolicy().to(device)\n",
    "\n",
    "# Test policy forward pass\n",
    "try:\n",
    "    policy_output = policy(state_dict)\n",
    "    print(\"Policy Output:\", policy_output)\n",
    "except Exception as e:\n",
    "    print(\"Error during policy forward pass:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CustomDragonEnv' object has no attribute 'observation_spec'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m share_parameters_critic \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      2\u001b[0m mappo \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# IPPO if False\u001b[39;00m\n\u001b[1;32m      4\u001b[0m critic_net \u001b[38;5;241m=\u001b[39m MultiAgentMLP(\n\u001b[0;32m----> 5\u001b[0m     n_agent_inputs\u001b[38;5;241m=\u001b[39m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobservation_spec\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magents\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobservation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m      6\u001b[0m     n_agent_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,  \u001b[38;5;66;03m# 1 value per agent\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     n_agents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(env\u001b[38;5;241m.\u001b[39magents),\n\u001b[1;32m      8\u001b[0m     centralised\u001b[38;5;241m=\u001b[39mmappo,\n\u001b[1;32m      9\u001b[0m     share_params\u001b[38;5;241m=\u001b[39mshare_parameters_critic,\n\u001b[1;32m     10\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m     11\u001b[0m     depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     12\u001b[0m     num_cells\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m,\n\u001b[1;32m     13\u001b[0m     activation_class\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mTanh,\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     16\u001b[0m critic \u001b[38;5;241m=\u001b[39m TensorDictModule(\n\u001b[1;32m     17\u001b[0m     module\u001b[38;5;241m=\u001b[39mcritic_net,\n\u001b[1;32m     18\u001b[0m     in_keys\u001b[38;5;241m=\u001b[39m[(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magents\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobservation\u001b[39m\u001b[38;5;124m\"\u001b[39m)],\n\u001b[1;32m     19\u001b[0m     out_keys\u001b[38;5;241m=\u001b[39m[(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magents\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate_value\u001b[39m\u001b[38;5;124m\"\u001b[39m)],\n\u001b[1;32m     20\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CustomDragonEnv' object has no attribute 'observation_spec'"
     ]
    }
   ],
   "source": [
    "share_parameters_critic = True\n",
    "mappo = True  # IPPO if False\n",
    "\n",
    "critic_net = MultiAgentMLP(\n",
    "    n_agent_inputs=env.observation_spec[\"agents\", \"observation\"].shape[-1],\n",
    "    n_agent_outputs=1,  # 1 value per agent\n",
    "    n_agents=len(env.agents),\n",
    "    centralised=mappo,\n",
    "    share_params=share_parameters_critic,\n",
    "    device=device,\n",
    "    depth=2,\n",
    "    num_cells=256,\n",
    "    activation_class=torch.nn.Tanh,\n",
    ")\n",
    "\n",
    "critic = TensorDictModule(\n",
    "    module=critic_net,\n",
    "    in_keys=[(\"agents\", \"observation\")],\n",
    "    out_keys=[(\"agents\", \"state_value\")],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "collector = SyncDataCollector(\n",
    "    env,\n",
    "    policy,\n",
    "    device=vmas_device,\n",
    "    storing_device=device,\n",
    "    frames_per_batch=frames_per_batch,\n",
    "    total_frames=total_frames,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = ReplayBuffer(\n",
    "    storage=LazyTensorStorage(\n",
    "        frames_per_batch, device=device\n",
    "    ),  # We store the frames_per_batch collected at each iteration\n",
    "    sampler=SamplerWithoutReplacement(),\n",
    "    batch_size=minibatch_size,  # We will sample minibatches of this size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_module = ClipPPOLoss(\n",
    "    actor_network=policy,\n",
    "    critic_network=critic,\n",
    "    clip_epsilon=clip_epsilon,\n",
    "    entropy_coef=entropy_eps,\n",
    "    normalize_advantage=False,  # Important to avoid normalizing across the agent dimension\n",
    ")\n",
    "loss_module.set_keys(  # We have to tell the loss where to find the keys\n",
    "    reward=env.reward_key,\n",
    "    action=env.action_key,\n",
    "    sample_log_prob=(\"agents\", \"sample_log_prob\"),\n",
    "    value=(\"agents\", \"state_value\"),\n",
    "    # These last 2 keys will be expanded to match the reward shape\n",
    "    done=(\"agents\", \"done\"),\n",
    "    terminated=(\"agents\", \"terminated\"),\n",
    ")\n",
    "\n",
    "\n",
    "loss_module.make_value_estimator(\n",
    "    ValueEstimators.GAE, gamma=gamma, lmbda=lmbda\n",
    ")  # We build GAE\n",
    "GAE = loss_module.value_estimator\n",
    "\n",
    "optim = torch.optim.Adam(loss_module.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for episode in range(num_episodes):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    episode_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        state_tensor = torch.tensor(state, dtype=torch.float32).to(device)\n",
    "        loc, scale = policy_net(state_tensor)\n",
    "\n",
    "        # Sample an action from the policy\n",
    "        dist = torch.distributions.Normal(loc, scale)\n",
    "        action = dist.sample()\n",
    "\n",
    "        # Step the environment\n",
    "        next_state, reward, done, _ = env.step(action.cpu().numpy())\n",
    "\n",
    "        # Calculate the loss and update the policy\n",
    "        # (This is just a placeholder, you need to implement your RL algorithm here)\n",
    "        loss = ...  # Compute your loss based on the chosen RL algorithm\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        state = next_state\n",
    "        episode_reward += reward\n",
    "\n",
    "    print(f\"Episode {episode + 1}, Reward: {episode_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode_reward_mean = 4.855388164520264: 100%|██████████| 15/15 [02:24<00:00,  9.98s/it]  "
     ]
    }
   ],
   "source": [
    "pbar = tqdm(total=n_iters, desc=\"episode_reward_mean = 0\")\n",
    "\n",
    "episode_reward_mean_list = []\n",
    "for tensordict_data in collector:\n",
    "    tensordict_data.set(\n",
    "        (\"next\", \"agents\", \"done\"),\n",
    "        tensordict_data.get((\"next\", \"done\"))\n",
    "        .unsqueeze(-1)\n",
    "        .expand(tensordict_data.get_item_shape((\"next\", env.reward_key))),\n",
    "    )\n",
    "    tensordict_data.set(\n",
    "        (\"next\", \"agents\", \"terminated\"),\n",
    "        tensordict_data.get((\"next\", \"terminated\"))\n",
    "        .unsqueeze(-1)\n",
    "        .expand(tensordict_data.get_item_shape((\"next\", env.reward_key))),\n",
    "    )\n",
    "    # We need to expand the done and terminated to match the reward shape (this is expected by the value estimator)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        GAE(\n",
    "            tensordict_data,\n",
    "            params=loss_module.critic_network_params,\n",
    "            target_params=loss_module.target_critic_network_params,\n",
    "        )  # Compute GAE and add it to the data\n",
    "\n",
    "    data_view = tensordict_data.reshape(-1)  # Flatten the batch size to shuffle data\n",
    "    replay_buffer.extend(data_view)\n",
    "\n",
    "    for _ in range(num_epochs):\n",
    "        for _ in range(frames_per_batch // minibatch_size):\n",
    "            subdata = replay_buffer.sample()\n",
    "            loss_vals = loss_module(subdata)\n",
    "\n",
    "            loss_value = (\n",
    "                loss_vals[\"loss_objective\"]\n",
    "                + loss_vals[\"loss_critic\"]\n",
    "                + loss_vals[\"loss_entropy\"]\n",
    "            )\n",
    "\n",
    "            loss_value.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                loss_module.parameters(), max_grad_norm\n",
    "            )  # Optional\n",
    "\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "\n",
    "    collector.update_policy_weights_()\n",
    "\n",
    "    # Logging\n",
    "    done = tensordict_data.get((\"next\", \"agents\", \"done\"))\n",
    "    episode_reward_mean = (\n",
    "        tensordict_data.get((\"next\", \"agents\", \"episode_reward\"))[done].mean().item()\n",
    "    )\n",
    "    episode_reward_mean_list.append(episode_reward_mean)\n",
    "    pbar.set_description(f\"episode_reward_mean = {episode_reward_mean}\", refresh=False)\n",
    "    pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(episode_reward_mean_list)\n",
    "plt.xlabel(\"Training iterations\")\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.title(\"Episode reward mean\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "ArgumentError",
     "evalue": "argument 2: <class 'TypeError'>: wrong type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArgumentError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 2\u001b[0m     \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mauto_cast_to_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbreak_when_any_done\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/ToM/lib/python3.9/site-packages/torchrl/envs/common.py:2564\u001b[0m, in \u001b[0;36mEnvBase.rollout\u001b[0;34m(self, max_steps, policy, callback, auto_reset, auto_cast_to_device, break_when_any_done, return_contiguous, tensordict, set_truncated, out)\u001b[0m\n\u001b[1;32m   2562\u001b[0m     tensordicts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rollout_stop_early(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   2563\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2564\u001b[0m     tensordicts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rollout_nonstop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2565\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;28;01mif\u001b[39;00m tensordict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m tensordict\u001b[38;5;241m.\u001b[39mbatch_size\n\u001b[1;32m   2566\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_contiguous:\n",
      "File \u001b[0;32m~/miniforge3/envs/ToM/lib/python3.9/site-packages/torchrl/envs/common.py:2700\u001b[0m, in \u001b[0;36mEnvBase._rollout_nonstop\u001b[0;34m(self, tensordict, auto_cast_to_device, max_steps, policy, policy_device, env_device, callback)\u001b[0m\n\u001b[1;32m   2698\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   2699\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2700\u001b[0m         \u001b[43mcallback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2702\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tensordicts\n",
      "Cell \u001b[0;32mIn[58], line 5\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(env, _)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      2\u001b[0m     env\u001b[38;5;241m.\u001b[39mrollout(\n\u001b[1;32m      3\u001b[0m         max_steps\u001b[38;5;241m=\u001b[39mmax_steps,\n\u001b[1;32m      4\u001b[0m         policy\u001b[38;5;241m=\u001b[39mpolicy,\n\u001b[0;32m----> 5\u001b[0m         callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m env, _: \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m      6\u001b[0m         auto_cast_to_device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m      7\u001b[0m         break_when_any_done\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m      8\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/ToM/lib/python3.9/site-packages/vmas/simulator/environment/environment.py:762\u001b[0m, in \u001b[0;36mEnvironment.render\u001b[0;34m(self, mode, env_index, agent_index_focus, visualize_when_rgb, plot_position_function, plot_position_function_precision, plot_position_function_range, plot_position_function_cmap_range, plot_position_function_cmap_alpha, plot_position_function_cmap_name)\u001b[0m\n\u001b[1;32m    759\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mviewer\u001b[38;5;241m.\u001b[39madd_onetime_list(entity\u001b[38;5;241m.\u001b[39mrender(env_index\u001b[38;5;241m=\u001b[39menv_index))\n\u001b[1;32m    761\u001b[0m \u001b[38;5;66;03m# render to display or array\u001b[39;00m\n\u001b[0;32m--> 762\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mviewer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreturn_rgb_array\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrgb_array\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/ToM/lib/python3.9/site-packages/vmas/simulator/rendering.py:149\u001b[0m, in \u001b[0;36mViewer.render\u001b[0;34m(self, return_rgb_array)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow\u001b[38;5;241m.\u001b[39mswitch_to()\n\u001b[0;32m--> 149\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwindow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_events\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform\u001b[38;5;241m.\u001b[39menable()\n\u001b[1;32m    153\u001b[0m text_lines \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniforge3/envs/ToM/lib/python3.9/site-packages/pyglet/window/xlib/__init__.py:939\u001b[0m, in \u001b[0;36mXlibWindow.dispatch_events\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    936\u001b[0m _view \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_view\n\u001b[1;32m    938\u001b[0m \u001b[38;5;66;03m# Check for the events specific to this window\u001b[39;00m\n\u001b[0;32m--> 939\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[43mxlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXCheckWindowEvent\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_x_display\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_window\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0x1ffffff\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    940\u001b[0m     \u001b[38;5;66;03m# Key events are filtered by the xlib window event\u001b[39;00m\n\u001b[1;32m    941\u001b[0m     \u001b[38;5;66;03m# handler so they get a shot at the prefiltered event.\u001b[39;00m\n\u001b[1;32m    942\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39mxany\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (xlib\u001b[38;5;241m.\u001b[39mKeyPress, xlib\u001b[38;5;241m.\u001b[39mKeyRelease):\n\u001b[1;32m    943\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m xlib\u001b[38;5;241m.\u001b[39mXFilterEvent(e, \u001b[38;5;241m0\u001b[39m):\n",
      "\u001b[0;31mArgumentError\u001b[0m: argument 2: <class 'TypeError'>: wrong type"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    env.rollout(\n",
    "        max_steps=max_steps,\n",
    "        policy=policy,\n",
    "        callback=lambda env, _: env.render(),\n",
    "        auto_cast_to_device=False,\n",
    "        break_when_any_done=False,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ToM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
